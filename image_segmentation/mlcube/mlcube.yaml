name: Image Segmentation
description: MLCommons Image Segmentation Training Reference Benchmark
authors: 
 - {name: "MLCommons Best Practices Working Group"}

platform:
  # Edit this according to your system specs
  accelerator_count: 1

container:
  # Image name.
  image: mlcommons/train_image_segmentation:0.0.1
  # Docker build context relative to $MLCUBE_ROOT. Default is `build`.
  build_context: "../pytorch"
  # Docker file name within docker build context, default is `Dockerfile`.
  build_file: "Dockerfile.mlcube"

tasks:
  # Download KiTS19 dataset
  download_data:
    io:
      # Directory for uncompressed datasets. Total size is ~ 29G.
      - {name: data_dir, type: directory, io: output, default: $WORKSPACE/data}
  preprocess_data:
  # Preprocess dataset
    io:
      # Same directory location where dataset was downloaded
      # When finished total size of the processed data is ~ 31G
      - {name: data_dir, type: directory, io: input, default: $WORKSPACE/data/kits19/data}
      - {name: processed_dir, type: directory, io: output, default: $WORKSPACE/processed_data}
  train:
  # Train image segmentation model
    io:
      # Same path from task preprocess_data::processed_dir
      - {name: data_dir, type: directory, io: input, default: $WORKSPACE/processed_data}
      # Output folder
      - {name: output_dir, type: directory, io: output, default: $WORKSPACE/output}
      # Yaml file with training parameters.
      - {name: parameters_file, type: file, io: input, default: $WORKSPACE/parameters.yaml}